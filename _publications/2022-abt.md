---
title: "Audio Barlow Twins: Self-Supervised Audio Representation Learning"
collection: publications
permalink: /publication/2022-abt
excerpt: ''
date: 2022/09/28
venue: 'arXiv'
paperurl: 'https://arxiv.org/abs/2209.14345'
biburl: /files/coppock2022abt.bib
citation: 'Jonah Anton, <b>Harry Coppock</b>, Pancham Shukla, Bjorn W.Schuller, Audio Barlow Twins: Self-Supervised Audio Representation Learning, arXiv, 2022'
author_profile: false
---
The Barlow Twins self-supervised learning objective requires neither negative samples or asymmetric learning updates, achieving results on a par with the current state-of-the-art within Computer Vision. As such, we present Audio Barlow Twins, a novel self-supervised audio representation learning approach, adapting Barlow Twins to the audio domain. We pre-train on the large-scale audio dataset AudioSet, and evaluate the quality of the learnt representations on 18 tasks from the HEAR 2021 Challenge, achieving results which outperform, or otherwise are on a par with, the current state-of-the-art for instance discrimination self-supervised learning approaches to audio representation learning. Code at this https URL.

[Download paper here](https://arxiv.org/abs/2209.14345)

<details closed>
<summary>Bibtex Entry</summary>
<code>
<pre>
@misc{anton2022abt,
  doi = {10.48550/ARXIV.2209.14345},
  url = {https://arxiv.org/abs/2209.14345},
  author = {Anton, Jonah and Coppock, Harry and Shukla, Pancham and Schuller, Bjorn W.},
  keywords = {Sound (cs.SD), Machine Learning (cs.LG), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {Audio Barlow Twins: Self-Supervised Audio Representation Learning},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}
</pre>
</code>
</details>